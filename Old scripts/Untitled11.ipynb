{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91cc3718-d121-4bd4-acd5-44eeaacaaecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24ebbf0-6fb6-4249-b493-eb25cdcee73f",
   "metadata": {},
   "source": [
    "Sets training configurations and loads the ProstateX labels. It ensures only patients with\n",
    "corresponding preprocessed .npy volume files are included in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ed0a1fd-da23-491e-be5b-85fb3ed9857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Config ===\n",
    "DATA_DIR = r\"C:\\Users\\anude\\Downloads\\processed_data\"\n",
    "FINDINGS_CSV = r\"C:\\Users\\anude\\Downloads\\project\\ProstateX-Findings-Train100.csv\"\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 10\n",
    "LR = 1e-4\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# === Load labels and volume paths ===\n",
    "df = pd.read_csv(FINDINGS_CSV)\n",
    "df = df.dropna(subset=['ClinSig'])\n",
    "df['ProxID'] = df['ProxID'].astype(str)\n",
    "df['ClinSig'] = df['ClinSig'].astype(int)\n",
    "\n",
    "# Only use IDs that have .npy files\n",
    "available_ids = {f.replace(\".npy\", \"\") for f in os.listdir(DATA_DIR)}\n",
    "df = df[df['ProxID'].isin(available_ids)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9bb1ea2-da67-4f46-8018-48172383c69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions\n",
    "\n",
    "def resize_volume(vol, target_shape=(3, 64, 64, 64)):\n",
    "    \"\"\"\n",
    "    Resizes a 4D volume by cropping or zero-padding to match the target shape.\n",
    "    Ensures consistent input dimensions for model training.\n",
    "    \"\"\"\n",
    "    c, d, h, w = vol.shape\n",
    "    tc, td, th, tw = target_shape\n",
    "    padded = np.zeros(target_shape, dtype=np.float32)\n",
    "    \n",
    "    # Crop if too big\n",
    "    d = min(d, td)\n",
    "    h = min(h, th)\n",
    "    w = min(w, tw)\n",
    "\n",
    "    padded[:c, :d, :h, :w] = vol[:c, :d, :h, :w]\n",
    "    return padded\n",
    "\n",
    "def load_tensor_dataset(dataframe, target_shape=(3, 64, 64, 64)):\n",
    "    \"\"\"\n",
    "    Loads and resizes volumes from .npy files, stacks them into tensors,\n",
    "    and returns a TensorDataset of image volumes and binary labels.\n",
    "    \"\"\"\n",
    "    x_list, y_list = [], []\n",
    "    for _, row in dataframe.iterrows():\n",
    "        try:\n",
    "            vol = np.load(os.path.join(DATA_DIR, f\"{row['ProxID']}.npy\")).astype(np.float32)\n",
    "            vol = resize_volume(vol, target_shape)\n",
    "            x_list.append(vol)\n",
    "            y_list.append(row['ClinSig'])\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Skipping {row['ProxID']}: {e}\")\n",
    "    x_tensor = torch.tensor(np.stack(x_list))  # [N, 3, 64, 64, 64]\n",
    "    y_tensor = torch.tensor(y_list, dtype=torch.float32)\n",
    "    return TensorDataset(x_tensor, y_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231a413b-5daa-49c8-b8f1-6ba454d490bb",
   "metadata": {},
   "source": [
    "Splits the dataset into stratified training and validation sets based on ClinSig, loads them as tensor datasets, and prepares PyTorch DataLoaders for model training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a8241f0d-6bdb-4ee5-b586-f5e11a0e74d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train/val\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['ClinSig'], random_state=42)\n",
    "\n",
    "train_data = load_tensor_dataset(train_df)\n",
    "val_data = load_tensor_dataset(val_df)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2312c9-77c4-407a-88d3-94fb13df15e7",
   "metadata": {},
   "source": [
    "A simple 3D CNN for binary classification of prostate lesions is trained using binary cross-entropy loss. After each epoch, the training loss is printed, and the model learns to predict clinical significance from the preprocessed 3D volumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a33cc094-6852-4ff3-9516-704069cdd98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 29/29 [00:03<00:00,  8.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Loss: 16.0126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 29/29 [00:03<00:00,  8.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Loss: 15.4384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 29/29 [00:03<00:00,  8.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Loss: 14.4914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 29/29 [00:03<00:00,  8.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Loss: 14.1233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 29/29 [00:03<00:00,  8.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Loss: 13.6600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 29/29 [00:03<00:00,  8.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Loss: 13.0406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 29/29 [00:03<00:00,  8.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Loss: 12.8113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 29/29 [00:03<00:00,  8.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Loss: 14.0870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 29/29 [00:03<00:00,  8.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Loss: 11.4950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 29/29 [00:03<00:00,  8.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Loss: 10.8940\n",
      " Model saved to C:\\Users\\anude\\Downloads\\project\\prostate_cnn_model_3d.pth\n"
     ]
    }
   ],
   "source": [
    "# === Define model ===\n",
    "model = nn.Sequential(\n",
    "    nn.Conv3d(3, 16, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool3d(2),\n",
    "    nn.Conv3d(16, 32, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool3d(2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(32 * 16 * 16 * 16, 128),  # adjust if input shape is different\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 1),\n",
    "    nn.Sigmoid()\n",
    ").to(DEVICE)\n",
    "\n",
    "# === Training ===\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x_batch, y_batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "        x_batch, y_batch = x_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x_batch).squeeze()\n",
    "        loss = loss_fn(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1} - Loss: {total_loss:.4f}\")\n",
    "\n",
    "# === Save model ===\n",
    "MODEL_PATH = r\"C:\\Users\\anude\\Downloads\\project\\prostate_cnn_model_3d.pth\"\n",
    "torch.save(model.state_dict(), MODEL_PATH)\n",
    "print(f\" Model saved to {MODEL_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad902a7f-f225-4005-87cc-1a51ab177ff9",
   "metadata": {},
   "source": [
    "Loads the saved 3D CNN model and evaluates its predictions on the validation set, calculating classification metrics like precision, recall, and F1-score for ClinSig and non-ClinSig cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "621a1fde-0686-45f6-8f11-68d8fd332e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Evaluation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Not ClinSig       0.79      0.96      0.86        23\n",
      "     ClinSig       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.76        29\n",
      "   macro avg       0.39      0.48      0.43        29\n",
      "weighted avg       0.62      0.76      0.68        29\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === Load saved model ===\n",
    "MODEL_PATH = r\"C:\\Users\\anude\\Downloads\\project\\prostate_cnn_model_3d.pth\"\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "# === Evaluation ===\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for x_batch, y_batch in val_loader:\n",
    "        x_batch = x_batch.to(DEVICE)\n",
    "        preds = model(x_batch).squeeze().cpu().numpy()\n",
    "        preds = (preds > 0.5).astype(int)\n",
    "        all_preds += [int(preds)] if np.isscalar(preds) else preds.tolist()\n",
    "        all_labels += [int(y_batch)] if torch.numel(y_batch) == 1 else y_batch.numpy().tolist()\n",
    "\n",
    "print(\"\\n📊 Evaluation Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=[\"Not ClinSig\", \"ClinSig\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc893bd-23d1-4ee1-be96-5d4a40f3e7d9",
   "metadata": {},
   "source": [
    "Visualises the confusion matrix to assess how well the model distinguishes between clinically significant and non-significant lesions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0d406fbc-e8a0-448c-ab07-4902e46f0d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Confusion Matrix ===\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Not ClinSig\", \"ClinSig\"])\n",
    "disp.plot(cmap=\"Blues\", values_format='d')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2576eb71-1919-4196-90f0-de0f0a69c8d5",
   "metadata": {},
   "source": [
    "<h2> Improving the accuracy and precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90e20b6-5a0c-4dbd-bd33-fa1485eef758",
   "metadata": {},
   "source": [
    "Adding focal loss, data augmentation, and oversampling of clinically significant cases to handle class imbalance. It uses a deeper CNN architecture with batch normalization, dropout, and a learning rate scheduler for better generalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ec1dd087-c917-4d28-9a70-b858549526c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = 3.0\n",
    "THRESHOLD = 0.5\n",
    "TARGET_SHAPE = (3, 64, 64, 64)\n",
    "EPOCHS = 30\n",
    "\n",
    "# === Data prep ===\n",
    "df = pd.read_csv(FINDINGS_CSV)\n",
    "df = df.dropna(subset=['ClinSig'])\n",
    "df['ProxID'] = df['ProxID'].astype(str)\n",
    "df['ClinSig'] = df['ClinSig'].astype(int)\n",
    "df['ProxID'] = df['ProxID'].apply(lambda x: x if x.startswith(\"ProstateX-\") else f\"ProstateX-{x}\")\n",
    "available_ids = {f.replace(\".npy\", \"\") for f in os.listdir(DATA_DIR)}\n",
    "df = df[df['ProxID'].isin(available_ids)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4d54b166-d10e-43b8-8a9d-bcd1328e19c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Focal Loss ===\n",
    "def focal_loss(logits, targets, gamma=GAMMA):\n",
    "    \"\"\"\n",
    "    Computes Focal Loss to address class imbalance by focusing more on hard-to-classify examples.\n",
    "    \"\"\"\n",
    "    bce = F.binary_cross_entropy_with_logits(logits, targets, reduction='none')\n",
    "    pt = torch.exp(-bce)\n",
    "    return ((1 - pt) ** gamma * bce).mean()\n",
    "\n",
    "\n",
    "# === Augmentation ===\n",
    "def augment(volume):\n",
    "    \"\"\"\n",
    "    Applies random 3D augmentations to a volume: horizontal flip, vertical flip, and 90-degree rotations.\n",
    "    \"\"\"\n",
    "    if random.random() < 0.5:\n",
    "        volume = np.flip(volume, axis=2)  # Horizontal\n",
    "    if random.random() < 0.5:\n",
    "        volume = np.flip(volume, axis=3)  # Vertical\n",
    "    if random.random() < 0.5:\n",
    "        k = random.choice([1, 2, 3])\n",
    "        volume = np.rot90(volume, k, axes=(2, 3)).copy()\n",
    "    return volume\n",
    "\n",
    "\n",
    "# === Resize + optional augment ===\n",
    "def resize_volume(vol, target_shape, augment_flag=False):\n",
    "    \"\"\"\n",
    "    Resizes a volume to the target shape by cropping or zero-padding, with optional augmentation.\n",
    "    \"\"\"\n",
    "    if augment_flag:\n",
    "        vol = augment(vol)\n",
    "    c, d, h, w = vol.shape\n",
    "    tc, td, th, tw = target_shape\n",
    "    padded = np.zeros(target_shape, dtype=np.float32)\n",
    "    d, h, w = min(d, td), min(h, th), min(w, tw)\n",
    "    padded[:c, :d, :h, :w] = vol[:c, :d, :h, :w]\n",
    "    return padded\n",
    "\n",
    "\n",
    "# === Data loader with augment for ClinSig ===\n",
    "def load_tensor_dataset(df, shape=TARGET_SHAPE, augment_clinsig=False):\n",
    "    \"\"\"\n",
    "    Loads volume data and labels into a TensorDataset, applying augmentation only to ClinSig-positive samples.\n",
    "    Returns the dataset and associated patient IDs.\n",
    "    \"\"\"\n",
    "    x_list, y_list, ids = [], [], []\n",
    "    for _, row in df.iterrows():\n",
    "        try:\n",
    "            vol = np.load(os.path.join(DATA_DIR, f\"{row['ProxID']}.npy\")).astype(np.float32)\n",
    "            is_clinsig = row['ClinSig'] == 1\n",
    "            vol = resize_volume(vol, shape, augment_flag=augment_clinsig and is_clinsig)\n",
    "            x_list.append(vol)\n",
    "            y_list.append(row['ClinSig'])\n",
    "            ids.append(row['ProxID'])\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Skipping {row['ProxID']}: {e}\")\n",
    "    x_tensor = torch.tensor(np.stack(x_list))\n",
    "    y_tensor = torch.tensor(y_list, dtype=torch.float32)\n",
    "    return TensorDataset(x_tensor, y_tensor), ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c95b5924-5e6c-4148-92cd-48dd96be024f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class distribution:\n",
      " ClinSig\n",
      "0    94\n",
      "1    44\n",
      "Name: count, dtype: int64\n",
      "Val class distribution:\n",
      " ClinSig\n",
      "0    23\n",
      "1     6\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === Train/val split + duplicate ClinSig once ===\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['ClinSig'], random_state=42)\n",
    "clinsig_df = train_df[train_df['ClinSig'] == 1]\n",
    "train_df = pd.concat([train_df, clinsig_df], ignore_index=True)\n",
    "\n",
    "# === Display counts ===\n",
    "print(\"Train class distribution:\\n\", train_df['ClinSig'].value_counts())\n",
    "print(\"Val class distribution:\\n\", val_df['ClinSig'].value_counts())\n",
    "\n",
    "# === Load Datasets ===\n",
    "train_data, _ = load_tensor_dataset(train_df, augment_clinsig=True)\n",
    "val_data, val_ids = load_tensor_dataset(val_df)\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9a8e5086-8dad-4b79-a669-61ef73246d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clearing GPU Chache\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d4d3d8-f183-4c2a-9e4d-c5d45750a531",
   "metadata": {},
   "source": [
    "A deep 3D CNN with batch normalization, dropout, and LeakyReLU activations, then trains it using focal loss and a learning rate scheduler. The model is optimised to handle class imbalance and learn robust features from volumetric prostate data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3c598dc6-3e54-46eb-8d03-263db6c1cd0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30:   3%|▎         | 1/35 [00:01<00:50,  1.49s/it]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 6.00 GiB of which 0 bytes is free. Of the allocated memory 1.62 GiB is allocated by PyTorch, and 48.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m x_batch, y_batch \u001b[38;5;241m=\u001b[39m x_batch\u001b[38;5;241m.\u001b[39mto(DEVICE), y_batch\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m     24\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 25\u001b[0m logits \u001b[38;5;241m=\u001b[39m model(x_batch)\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[0;32m     26\u001b[0m loss \u001b[38;5;241m=\u001b[39m focal_loss(logits, y_batch)\n\u001b[0;32m     27\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:70\u001b[0m, in \u001b[0;36mDropout.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minplace)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\functional.py:1425\u001b[0m, in \u001b[0;36mdropout\u001b[1;34m(input, p, training, inplace)\u001b[0m\n\u001b[0;32m   1422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[0;32m   1423\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1424\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m-> 1425\u001b[0m     _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28minput\u001b[39m, p, training)\n\u001b[0;32m   1426\u001b[0m )\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 6.00 GiB of which 0 bytes is free. Of the allocated memory 1.62 GiB is allocated by PyTorch, and 48.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# === Deep CNN Model ===\n",
    "model = nn.Sequential(\n",
    "    nn.Conv3d(3, 16, 3, padding=1), nn.BatchNorm3d(16), nn.LeakyReLU(),\n",
    "    nn.Conv3d(16, 32, 3, padding=1), nn.BatchNorm3d(32), nn.LeakyReLU(),\n",
    "    nn.MaxPool3d(2),\n",
    "    nn.Conv3d(32, 64, 3, padding=1), nn.BatchNorm3d(64), nn.LeakyReLU(),\n",
    "    nn.MaxPool3d(2),\n",
    "    nn.Flatten(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(64 * 16 * 16 * 16, 256), nn.LeakyReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(256, 1)\n",
    ").to(DEVICE)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5)\n",
    "\n",
    "# === Training Loop ===\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x_batch, y_batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "        x_batch, y_batch = x_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x_batch).squeeze()\n",
    "        loss = focal_loss(logits, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1} - Loss: {total_loss:.4f}\")\n",
    "    scheduler.step(total_loss)\n",
    "\n",
    "# === Save Trained Model ===\n",
    "MODEL_PATH = r\"C:\\Users\\anude\\Downloads\\project\\prostate_cnn_model_3DCNN.pth\"\n",
    "torch.save(model.state_dict(), MODEL_PATH)\n",
    "print(f\" Model saved to {MODEL_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8fcef7-806c-4690-a0f6-85f037795233",
   "metadata": {},
   "source": [
    "Evaluates the model on the validation set using sigmoid-based thresholding and prints a classification report, displays example predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64107ccc-ef8a-4f9e-a70e-61fa0e627513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load Saved Model ===\n",
    "MODEL_PATH = r\"C:\\Users\\anude\\Downloads\\project\\prostate_cnn_model_3DCNN.pth\"\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "# === Evaluation ===\n",
    "all_preds, all_labels, all_proxids = [], [], []\n",
    "index = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_batch, y_batch in val_loader:\n",
    "        x_batch = x_batch.to(DEVICE)\n",
    "        logits = model(x_batch).squeeze()\n",
    "        probs = torch.sigmoid(logits).cpu().numpy()\n",
    "        preds = (probs > THRESHOLD).astype(int)\n",
    "        preds = np.atleast_1d(preds)\n",
    "        y_batch = y_batch.numpy()\n",
    "        for i in range(len(preds)):\n",
    "            prox_id = val_ids[index]\n",
    "            all_proxids.append(prox_id)\n",
    "            all_preds.append(int(preds[i]))\n",
    "            all_labels.append(int(y_batch[i]))\n",
    "            index += 1\n",
    "\n",
    "# === Report ===\n",
    "print(\"\\nFinal Evaluation Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=[\"Not ClinSig\", \"ClinSig\"], zero_division=0))\n",
    "\n",
    "print(\"\\nSample Predictions:\")\n",
    "for pid, pred, label in zip(all_proxids[:10], all_preds[:10], all_labels[:10]):\n",
    "    print(f\"{pid}: Predicted={pred}, Actual={label}\")\n",
    "\n",
    "# === Confusion Matrix ===\n",
    "cm = confusion_matrix(all_labels, all_preds, labels=[0, 1])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Not ClinSig\", \"ClinSig\"])\n",
    "plt.figure(figsize=(5, 4))\n",
    "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
